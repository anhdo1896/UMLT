{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Classification\n",
    "# Using Machine Learning Tools\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this assignment, you will apply some popular machine learning techniques to the problem of classifying data from histological cell images for the diagnosis of malignant breast cancer. This will be presented as a practical scenario where you are approached by a client to solve a problem.  \n",
    "\n",
    "The main aims of this assignment are: \n",
    "\n",
    "- to use the best practice machine learning workflow for producing a solution to a client's problem;\n",
    "- to visualise data and determine the best pre-processing;\n",
    "- to create the necessary datasets for training and testing purposes;\n",
    "- to train and optimise a selection of models, then choose the best;\n",
    "- to obtain an unbiased measurement of the final model's performance;\n",
    "- to interpret results clearly and concisely.\n",
    "\n",
    "This assignment relates to the following ACS CBOK areas: abstraction, design, hardware and software, data and information, HCI and programming.\n",
    "\n",
    "## General instructions\n",
    "\n",
    "This assignment is divided into several tasks. Use the spaces provided in this notebook to answer the questions posed in each task. Note that some questions require writing a small amount of code, some require graphical results, and some require comments or analysis as text. It is your responsibility to make sure your responses are clearly labelled and your code has been fully executed (**with the correct results displayed**) before submission!\n",
    "\n",
    "**Do not** manually edit the data set file we have provided! For marking purposes, it's important that your code runs correctly on the original data file.\n",
    "\n",
    "Some of the parts of this assignment build on the workflow from the first assignment and that part of the course, and so less detailed instructions are provided for this, as you should be able to implement this workflow now without low-level guidance. A substantial portion of the marks for this assignment are associated with making the right choices and executing this workflow correctly and efficiently. Make sure you have clean, readable code as well as producing outputs, since your coding will also count towards the marks (however, excessive commenting is discouraged and will lose marks, so aim for a modest, well-chosen amount of comments and text in outputs).\n",
    "\n",
    "This assignment can be solved using methods from [sklearn](https://scikit-learn.org/stable/index.html), [pandas](https://pandas.pydata.org/pandas-docs/stable/index.html), and [matplotlib](https://matplotlib.org/stable/index.html) as presented in the workshops. Other libraries should not be used (even though they might have nice functionality) and certain restrictions on sklearn functions will be made clear in the instruction text. You are expected to search and carefully read the documentation for functions that you use, to ensure you are using them correctly."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenario\n",
    "\n",
    "A client approaches you to solve a machine learning problem for them.  They run a pathology lab that processes histological images for healthcare providers and they have created a product that measures the same features as in the *Wisconsin breast cancer data set* though using different acquisitions and processing methods. This makes their method much faster than existing ones, but it is also slightly noisier. They want to be able to diagnose *malignant* cancer (and distinguish them from *benign* growths) by employing machine learning techniques, and they have asked you to implement this for them.\n",
    "\n",
    "Their requirements are:\n",
    " 1) have at least a 95% probability of detecting malignant cancer when it is present;\n",
    " 2) have no more than 1 in 10 healthy cases (those with benign tumours) labelled as positive (malignant).\n",
    " \n",
    "They have hand-labelled 300 samples for you, which is all they have at the moment.\n",
    "\n",
    "Please follow the instructions below, which will vary in level of detail, as appropriate to the marks given."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Investigate Dataset (10% = 3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code imports some libraries that you will need. \n",
    "# You should not need to modify it, though you are expected to make other imports later in your code.\n",
    "\n",
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Pandas for overview\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Plot setup\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=7)\n",
    "mpl.rc('xtick', labelsize=6)\n",
    "mpl.rc('ytick', labelsize=6)\n",
    "mpl.rc('figure', dpi=240)\n",
    "plt.close('all')\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load the dataset [0.5 marks]\n",
    "Do this from the csv file, `assignment2.csv`, as done in assignment 1 and workshops 2 and 3. Extract the feature names and label names for use later on.  Note that we will be treating the _malignant_ case as our _positive_ case, as this is the standard convention in medicine.\n",
    "\n",
    "**Print out some information (in text) about the data, to verify that the loading has worked and to get a feeling for what is present in the dataset and the range of the values.**\n",
    "\n",
    "**Also, graphically show the proportions of the labels in the whole dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.2 Visualise the dataset [1.5 marks]\n",
    "\n",
    "As this data is well curated by the client already, you do not need to worry about outliers, missing values or imputation in this case, but be aware that this is the exception, not the rule.\n",
    "\n",
    "To familiarise yourself with the nature and information contained in the data, display histograms for the data according to the following instructions:\n",
    " - **display histograms** for each feature in the _mean_ group, but on _each_ histogram **have the two classes displayed together in one plot** (see example plot below and a code fragment to help you) - and note that your plot does not need to look exactly the example here;\n",
    " - **repeat this** for the _standard error_ and _worst_ groups;\n",
    " - make sure that in all cases you clearly label the plots and the classes in histograms.\n",
    "\n",
    "<center><img src=\"Example_Hist_Plot.png\" width=\"300\" alt=\"Example plot of histogram\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code fragment to help with plotting histograms combining matplotlib and seaborn (and pandas)\n",
    "fig, axes = plt.subplots(Nrows, Ncols, figsize=(?, ?))\n",
    "...\n",
    "sns.histplot(data=df, x=??, hue=\"??\", bins=??, kde=True, ax=axes[row,col], edgecolor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Ranking the features [0.5 marks]\n",
    "\n",
    "**Based on the histograms, which do you think are the 3 strongest features for discriminating between the classes?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1.4 Splitting the dataset [0.5 marks]\n",
    "\n",
    "Split the dataset into appropriate subsets. You must choose what the subsets are and how big they are. However, we want to make sure the proportion of the two classes is consistent across all datasets, so use the _stratify_ option, as used in workshops 5 and 6. Verify the size and label distribution in each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build, Train and Optimise Classifiers (60% = 18 marks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Pipeline [0.5 marks]\n",
    "**Build a pre-processing pipeline** that includes imputation (as even though we don't strictly need it here it is a good habit to always include it) and other appropriate pre-processing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Baseline measurements [1.5 marks]\n",
    "\n",
    "For our classification task we will consider **three simple baseline cases**:\n",
    "1) predicting all samples to be negative (class 1)\n",
    "2) predicting all samples to be positive (class 2)\n",
    "3) making a random prediction for each sample with equal probability for each class\n",
    "\n",
    "**For each case measure and display the following metrics:**\n",
    " - balanced accuracy\n",
    " - recall\n",
    " - precision\n",
    " - auc\n",
    " - f1score\n",
    " - fbeta_score with beta=0.1\n",
    " - fbeta_score with beta=10\n",
    "\n",
    "Code is given below for the latter metrics (all metrics are discussed in lecture 4 and many are in workshop 4).\n",
    "\n",
    "Also **calculate and display the confusion matrix** for each baseline case, using a heatmap and numbers (as in workshop 4). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "\n",
    "f10_scorer = make_scorer(fbeta_score, beta=10)\n",
    "f01_scorer = make_scorer(fbeta_score, beta=0.1)\n",
    "\n",
    "def f10_score(yt,yp):\n",
    "    return fbeta_score(yt, yp, beta=10)\n",
    "\n",
    "def f01_score(yt,yp):\n",
    "    return fbeta_score(yt, yp, beta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3 Choose a performance metric [0.5 marks]\n",
    "\n",
    "Based on the above baseline tests and the client's requirements, **choose a performance metric** to use for evaluating/driving your machine learning methods.  **Give a reason for your choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 SGD baseline [1 mark]\n",
    "\n",
    "For a stronger baseline, **train and evaluate** the Stochastic Gradient Descent classifier (as seen in workshop 5). For this baseline case use the default settings for all the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Confusion matrix [1 mark]\n",
    "\n",
    "Calculate and display the normalized version of the confusion matrix.  From this **calculate the _probability_ that a sample from a person with a malignant tumour is given a result that they do not have cancer.  Which of the client's two criteria does this relate to, and is this baseline satisfying this criterion or not?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.6 Main classifier [11 marks]\n",
    "\n",
    "**Train and optimise the hyperparameters** to give the best performance for **each of the following classifiers**:\n",
    " - KNN (K-Nearest Neighbour) classifier\n",
    " - Decision tree classifier\n",
    " - Support vector machine classifier\n",
    " - SGD classifier\n",
    " \n",
    "Follow best practice as much as possible here. You must make all the choices and decisions yourself, and strike a balance between computation time and performance.\n",
    "\n",
    "You can use any of the sci-kit learn functions in sklearn.model_selection.cross* and anything used in workshops 3, 4, 5 and 6. Other hyper-parameter optimisation functions apart from these cannot be used (even if they are good and can be part of best practice in other situations - for this assignment everyone should assume they only have very limited computation resources and limit themselves to these functions).\n",
    "\n",
    "**Display the performance of the different classifiers and the optimised hyperparameters.**\n",
    "\n",
    "**Based on these results, list the best 3 classifiers and indicate if you think any perform equivalently.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.7 Model selection [1 mark]\n",
    "\n",
    "**Choose the best classifier** (as seen in workshops 3 to 6) and give details of your hyperparameter settings. **Explain the reason for your choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Final performance [1.5 marks]\n",
    "\n",
    "**Calculate and display an unbiased performance measure that you can present to the client.**\n",
    "\n",
    "**Is your chosen classifier underfitting or overfitting?**\n",
    "\n",
    "**Does your chosen classifier meet the client's performance criteria?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your answers here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Decision Boundaries (15% = 4.5 marks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Rank features [1 mark]\n",
    "\n",
    "Although it is only possible to know the true usefulness of a feature when you've combined it with others in a machine learning method, it is still helpful to have some measure for how discriminative each feature is on its own.  One common method for doing this is to calculate a T-score (often used in statistics, and in the LDA machine learning method) for each feature.  \n",
    "\n",
    "The formula for the T-score is (mean(x2) - mean(x1))/(0.5*(stddev(x2) + stddev(x1))), where x1 and x2 are the datasets corresponding to the two classes. Large values for the T-score (either positive or negative) indicate discriminative ability.\n",
    "\n",
    "**Calculate the T-score for each feature and print out the best 4 features according to this score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualise decision boundaries [2.5 marks]\n",
    "\n",
    "**Display the decision boundaries** for each pair of features from the best 4 chosen above.  You can use the DecisionBoundaryDisplay function (as per workshop 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Interpretation [1 mark]\n",
    "\n",
    "From the decision boundaries displayed above, **would you expect the method to extrapolate well or not**?  Give reasons for your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Second Round (15% = 4.5 marks)\n",
    "\n",
    "After presenting your initial results to the client they come back to you and say that they have done some financial analysis and it would save them a lot of time and money if they did not have to analyse every cell, which is needed to get the \"worst\" features. Instead, they can quickly get accurate estimates for the \"mean\" and \"standard error\" features from a much smaller, randomly selected set of cells.\n",
    "\n",
    "They ask you to **give them a performance estimate for the same problem, but without using any of the \"worst\" features.**\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 New estimate [3.5 marks]\n",
    "\n",
    "**Calculate an unbiased performance estimate** for this new problem, as requested by the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Performance difference [1 mark]\n",
    "\n",
    "Do you think the new classifier, that does not use the \"worst\" features, is:\n",
    " - **as good as the previous classifier** (that uses all the features)\n",
    " - **better than the previous classifier**\n",
    " - **worse than the previous classifier**\n",
    " \n",
    "Give reasons for your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
